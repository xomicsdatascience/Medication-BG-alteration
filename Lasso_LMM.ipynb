{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c7bd94-92fe-49a5-846d-bdeaabe5e3df",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfda63-50e5-4319-9aa0-1ec38d446b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_squared_error, r2_score, PredictionErrorDisplay\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import PolynomialFeatures  \n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedKFold,cross_validate\n",
    "import scipy as sp \n",
    "import statsmodels.api\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35ea868-498f-4ca9-b8f5-f15c88738cf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pre-process demographic and social history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4ab6a-6e1e-42b0-92d8-8fc726890cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo = pd.read_csv(r'C:\\Users\\momenzadeha\\Documents\\hypogly_pred\\EHR_extracts\\meyer_2306_encounters_major_class_2023_05_30.csv')\n",
    "SH = pd.read_excel(r'C:\\Users\\momenzadeha\\Documents\\hypogly_pred\\EHR_extracts\\Patient Info.xlsx')\n",
    "with open(r'C:\\Users\\momenzadeha\\Documents\\mixed effects LR\\LMM\\MELRoutputCSNs.pkl', 'rb') as handle:\n",
    "    CSN_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ccf54-a32d-44d8-b5ce-f57a534ce965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_static_inputs(demo, SH, CSN_list):\n",
    "    demo_MRN = demo[['MRN', 'CSN', 'CONTACT_DATE', 'BMI', 'DPT_NAME']].drop_duplicates()\n",
    "    SH_CSN = demo_MRN.merge(SH, on='MRN', how='inner')\n",
    "    # Create a DataFrame from CSN_list and merge with SH_CSN on 'CSN'\n",
    "    master_CSN = pd.DataFrame(CSN_list, columns=['CSN'])\n",
    "    static_inputs = master_CSN.merge(SH_CSN, on='CSN', how='left')\n",
    "    # Select and drop duplicate columns\n",
    "    static_inputs = static_inputs[['CSN', 'MRN', 'CONTACT_DATE', 'BMI', 'BIRTH_DATE', 'ETHNIC_GROUP',\n",
    "                                   'SEX', 'RACE_1', 'SMOKE_TOB_LAST_STATUS', 'ILL_DRUG_LAST_STATUS',\n",
    "                                   'ALCOHOL_LAST_STATUS', 'DPT_NAME']].drop_duplicates()\n",
    "    # Calculate age in years\n",
    "    static_inputs['AGE'] = ((pd.to_datetime(static_inputs['CONTACT_DATE']) - pd.to_datetime(static_inputs['BIRTH_DATE'])) \n",
    "                            / np.timedelta64(1, 'D')) / 365\n",
    "    static_inputs = static_inputs[['MRN', 'CSN', 'AGE', 'BMI', 'ETHNIC_GROUP', 'SEX', 'RACE_1',\n",
    "                                   'SMOKE_TOB_LAST_STATUS', 'ILL_DRUG_LAST_STATUS', 'ALCOHOL_LAST_STATUS',\n",
    "                                   'DPT_NAME']]\n",
    "    static_inputs['MRN'] = static_inputs['MRN'].round().astype('Int64')\n",
    "    return static_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a901c-6054-4baa-b77f-a41e61327308",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_inputs = prepare_static_inputs(demo, SH, CSN_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb7d33-be17-4c70-807a-feecad02bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_admit_diag(demo):\n",
    "    admit_diag = demo[['MRN', 'CSN', 'ADMIT_DIAG']]\n",
    "    return admit_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d55f98-b8ed-49b4-bfaf-cdf8033bea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_diag = extract_admit_diag(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ef0e3-f4cf-47db-981d-4f264ec0af00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_admission_diagnoses(admit_diag):\n",
    "    # Define diagnosis patterns and corresponding column names\n",
    "    diagnosis_dict = {\n",
    "        'Admit_CHF': [\n",
    "            'Acute on chronic congestive heart failure, unspecified heart failure type (HCC)',\n",
    "            'Systolic CHF, acute on chronic (HCC)',\n",
    "            'Congestive heart failure, unspecified HF chronicity, unspecified heart failure type (HCC)',\n",
    "            'CHF',\n",
    "            'Acute congestive heart failure, unspecified heart failure type (HCC)'\n",
    "        ],\n",
    "        'Admit_Sepsis': [\n",
    "            'Sepsis, due to unspecified organism',\n",
    "            'Sepsis, due to unspecified organism, unspecified whether acute organ dysfunction present (HCC)',\n",
    "            'Sepsis',\n",
    "            'Severe sepsis (HCC)',\n",
    "            'Septic shock (HCC)'\n",
    "        ],\n",
    "        'Admit_GIB': [\n",
    "            'gastrointestinal bleed',\n",
    "            'GI bleed',\n",
    "            'UGIB',\n",
    "            'Gastrointestinal hemorrhage, unspecified gastrointestinal hemorrhage type'\n",
    "        ],\n",
    "        'Admit_NV': [\n",
    "            'Nausea and vomiting, intractability of vomiting not specified, unspecified vomiting type',\n",
    "            'Non-intractable vomiting with nausea, unspecified vomiting type',\n",
    "            'Intractable vomiting with nausea, unspecified vomiting type'\n",
    "        ],\n",
    "        'Admit_AMS': [\n",
    "            'Altered mental status, unspecified altered mental status type'\n",
    "        ],\n",
    "        'Admit_AKI': [\n",
    "            'Acute kidney injury (HCC)',\n",
    "            'Acute renal failure, unspecified acute renal failure type (HCC)',\n",
    "            'Renal insufficiency',\n",
    "            'Acute renal insufficiency'\n",
    "        ],\n",
    "        'Admit_ESRD': [\n",
    "            'ESRD on dialysis (HCC)',\n",
    "            'Chronic kidney disease, unspecified CKD stage',\n",
    "            'ESRD',\n",
    "            'ESRD on hemodialysis (HCC)'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Iterate over diagnosis patterns and classify each diagnosis\n",
    "    for column, patterns in diagnosis_dict.items():\n",
    "        pattern = '|'.join(patterns)\n",
    "        admit_diag[column] = np.where(admit_diag['ADMIT_DIAG'].str.contains(pattern, case=False, na=False), 1, 0)\n",
    "    admit_diag['Admit_Pain'] = np.where(admit_diag['ADMIT_DIAG'].str.contains('pain', case=False, na=False), 1, 0)\n",
    "    admit_diag.drop(['ADMIT_DIAG', 'MRN'], axis=1, inplace=True)\n",
    "    admit_diag = admit_diag.groupby('CSN').sum()\n",
    "    admit_diag[admit_diag > 1] = 1  \n",
    "    admit_diag.reset_index(inplace=True)\n",
    "    return admit_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65f7a3-6af6-43a0-85f5-ba828938eff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "admit_diag=classify_admission_diagnoses(admit_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aeca38-dbdf-4756-9d33-ac4b0995ee69",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pre-process past medical history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db77deb-5c64-44f6-a6e3-758b58088359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PMH = pd.read_csv(r'C:\\Users\\momenzadeha\\Documents\\hypogly_pred\\EHR_extracts\\Meyer2306 Diagnosis Hx.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d40bfd-a13c-452c-a36d-620f59796cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_pmh_with_icd10(pmh_df):\n",
    "    # Define ICD-10 patterns and corresponding column names\n",
    "    icd10_dict = {\n",
    "        'PMH_Liver_failure': 'K72',\n",
    "        'PMH_CKD': 'N18',\n",
    "        'PMH_T1DM': 'E10',\n",
    "        'PMH_T2DM': 'E11',\n",
    "        'PMH_CHF': 'I50',\n",
    "        'PMH_HypoThyroid': 'E03.0',\n",
    "        'PMH_HyperThyroid': 'E05',\n",
    "        'PMH_Pregnancy': 'Z33.1',\n",
    "        'PMH_Anemia': 'D64.9',\n",
    "        'PMH_Hypoglycemia': 'E16.2',\n",
    "        'PMH_Malignancy': 'C80.1',\n",
    "        'PMH_Pain': 'R52'\n",
    "    }\n",
    "    for column, pattern in icd10_dict.items():\n",
    "        pmh_df[column] = pmh_df['CURRENT_ICD10_LIST'].str.contains(pattern, na=False).astype(int)\n",
    "    pmh_df = (pmh_df[['MRN'] + list(icd10_dict.keys())]\n",
    "              .groupby('MRN')\n",
    "              .sum()\n",
    "              .clip(upper=1))\n",
    "    return pmh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58c6f1-efeb-4d6e-bb19-525a9f1adad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMH = update_pmh_with_icd10(PMH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e803e-920f-49a3-a7b6-b8441e92d48f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Read in meds input previously made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6226cf-7c27-489f-b80c-a8efb51c0082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(r'/Users/momenzadeha/Documents/mixed effects LR/LMM/top500_DM_meds_24h.pkl', 'rb') as handle:\n",
    "    top500_DM_meds = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ad119-9dcd-4f72-a261-d78ca89c182a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Read in labs input previously made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e91e9-9eba-4cc3-8887-b4f1225b1aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(r'/Users/momenzadeha/Documents/mixed effects LR/LMM/sel_labs_24h.pkl', 'rb') as handle:\n",
    "    sel_labs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632b8e9-d30b-434e-b7a0-4f2f0deed641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean and rename columns in the DataFrame `sel_labs`\n",
    "def clean_and_rename_columns(df):\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        parts = col.split(',')\n",
    "        if len(parts) >= 2:\n",
    "            # Extract and clean the second part of the split column name\n",
    "            second_part = parts[1].strip().replace(\"(\", \"\").replace(\")\", \"\").replace(\" \", \"\").replace(\"'\", \"\")\n",
    "            new_columns.append(second_part)\n",
    "        else:\n",
    "            # Keep the original column name if it doesn't split into at least two parts\n",
    "            new_columns.append(col.replace(\"'\", \"\"))\n",
    "    df.columns = new_columns\n",
    "    df = df[['CSN', 'CREATININE_mean', 'GLUCOSE-POC_mean', 'GLUCOSE-POC_min', 'GLUCOSE-POC_last', 'GLUCOSE-POC_max']]\n",
    "    df = df.set_index('CSN')\n",
    "    # Remove rows with NaN values\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11986e80-c5ca-48b3-ab5c-22d0b9d0f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_labs = clean_and_rename_columns(sel_labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32130719-a47f-4a1b-90d4-1cc163b17f02",
   "metadata": {},
   "source": [
    "#### read in output BG previously made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d2e92-c0a4-46a2-888a-e7b2fb3b8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/momenzadeha/Documents/mixed effects LR/LMM/outputBG_df.pkl', 'rb') as handle:\n",
    "    outputBG = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216121da-cf71-4e50-9f31-85938f5e56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and select relevant columns in `outputBG`\n",
    "outputBG = outputBG.rename(columns={'PAT_ENC_CSN_ID': 'CSN'})[['CSN', 'ORD_VALUE']]\n",
    "# Merge with `static_inputs` and filter out rows with missing MRN\n",
    "static_output_df = outputBG.merge(static_inputs, on='CSN', how='inner').dropna(subset=['MRN']).reset_index(drop=True)\n",
    "# Perform successive merges to combine data\n",
    "med_lab_static = top500_DM_meds.merge(static_output_df, on='CSN', how='inner')\n",
    "med_lab_static_PMH = med_lab_static.merge(sel_labs, on='CSN', how='inner')\n",
    "med_lab_static_PMH_admdx = med_lab_static_PMH.merge(PMH, on='MRN', how='inner').merge(admit_diag, on='CSN', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e45df-e9c9-455a-8603-ce4343439288",
   "metadata": {
    "tags": []
   },
   "source": [
    "### one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5268b2-907a-4992-b43f-e29f65a4bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['ETHNIC_GROUP', 'SEX', 'RACE_1', 'SMOKE_TOB_LAST_STATUS', \n",
    "                        'ILL_DRUG_LAST_STATUS', 'ALCOHOL_LAST_STATUS']\n",
    "# Replace NaN values with the string 'Missing' for the selected columns\n",
    "med_lab_static_PMH_admdx[categorical_columns] = med_lab_static_PMH_admdx[categorical_columns].fillna('Missing')\n",
    "# One-hot encode the categorical columns\n",
    "med_lab_static_PMH_admdx = pd.get_dummies(med_lab_static_PMH_admdx, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef865ae4-de82-4e98-8b87-8ee01ae2b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove missing BMIs (0.7% of encounters)\n",
    "med_lab_static_PMH_admdx=med_lab_static_PMH_admdx.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624df1d9-c3e8-437a-b7fe-2f3a8d2d77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define OR departments \n",
    "OR_depts = [\n",
    "    '6-ACU (6-PACU)', '8-ACU (8-PACU)', '3-ACU (3-PACU)', '7GI-ACU (GI LAB PACU)', '6-PACU', '7-PACU', '5-PACU', '7-ACU (7-PACU)',\n",
    "    'GI LAB MAIN', '8-OR', '6-OR', '5-OR', 'CARDIAC CATH LAB MAIN', 'AHSP 5-PACU', '3-PACU', 'INTERVENTION RAD MAIN', '8-PRE-OP', \n",
    "    '8-PACU', '7-OR', '3-PREOP', 'RT BRONCHOSCOPY MAIN', '5-ACU (5-PACU)'\n",
    "]\n",
    "# Map for ICU and non-ICU replacement\n",
    "dept_replacement_map = {\n",
    "    'non_ICU': [\n",
    "        '6-NE', '6-NW', '4-NW', '5-NW', '5-NE', '5-SE', '7-SE', '5-SW', '6-SE', '8-NE', '6-SW', '3-N', '7-NE', '7-NW', '4-SE',\n",
    "        '7-SW', '4-SW', '8-NW', '3N-UNIV', '8-SE', '8-SW', '3S-UNIV', '3SPT', 'MDRH 1 SOUTH', 'MDRH 1 NORTH', '3-SW', '3-SE',\n",
    "        '3-SW OB', '3-NW', '7 REHAB', '6-ACU (6-PACU)', 'MDRH MED SSU', '8-ACU (8-PACU)', '4S-MON', 'MDRH 1 EAST', '3-ACU (3-PACU)',\n",
    "        '7GI-ACU (GI LAB PACU)', '3-N MFCU', '3-NE', '6-PACU', '4-NE', 'OLD PEDS 4-NE', 'AHSP 5-ACU', '7-PACU', '5-PACU', '7-ACU (7-PACU)',\n",
    "        'GI LAB MAIN', '8-OR', '3-SE OB', '6-OR', '5-OR', 'AHSP 5-OSU', 'CARDIAC CATH LAB MAIN', 'AHSP 5-PACU', '3-PACU', \n",
    "        'MDRH EMERGENCY DEPT', '2-SCCT PEDS', 'INTERVENTION RAD MAIN', '8-PRE-OP', '8-PACU', '7-OR', '3-PREOP', '3-LDR',\n",
    "        'RT BRONCHOSCOPY MAIN', 'DIALYSIS ACUTE MAIN', '5-ACU (5-PACU)'\n",
    "    ],\n",
    "    'ICU': [\n",
    "        '6-ICU', '8S-NSICU', '8N-ICU', '7S-RICU', '7N-MICU', '4N-CICU', '5S-SICU', '5N-SICU', '5N-SICU', '6S-CSICU', '6N-CSICU',\n",
    "        '4S-ICU', 'MDRH INTENSIVE CARE', '4S-PICU'\n",
    "    ]\n",
    "}\n",
    "# Function to categorize departments\n",
    "def categorize_dept(dept_name):\n",
    "    if dept_name in OR_depts:\n",
    "        return 'OR'\n",
    "    elif dept_name in dept_replacement_map['non_ICU']:\n",
    "        return 'non_ICU'\n",
    "    elif dept_name in dept_replacement_map['ICU']:\n",
    "        return 'ICU'\n",
    "    else:\n",
    "        return 'Other'\n",
    "# Apply the function to create admit_dept column\n",
    "med_lab_static_PMH_admdx['admit_dept'] = med_lab_static_PMH_admdx['DPT_NAME'].apply(categorize_dept)\n",
    "# One-hot encode the admit_dept column\n",
    "one_hot = pd.get_dummies(med_lab_static_PMH_admdx['admit_dept'], prefix='admit_dept')\n",
    "# Drop the original admit_dept column and join the one-hot encoded columns\n",
    "med_lab_static_PMH_admdx = med_lab_static_PMH_admdx.drop('admit_dept', axis=1).join(one_hot)\n",
    "# Replace DPT_NAME values\n",
    "med_lab_static_PMH_admdx['DPT_NAME'] = med_lab_static_PMH_admdx['DPT_NAME'].replace({\n",
    "    '6-ICU': 'ICU', '8S-NSICU': 'ICU', '8N-ICU': 'ICU', '7S-RICU': 'ICU', '7N-MICU': 'ICU', '4N-CICU': 'ICU',\n",
    "    '5S-SICU': 'ICU', '5N-SICU': 'ICU', '6S-CSICU': 'ICU', '6N-CSICU': 'ICU', '4S-ICU': 'ICU', 'MDRH INTENSIVE CARE': 'ICU',\n",
    "    '4S-PICU': 'ICU'\n",
    "})\n",
    "# One-hot encode the updated DPT_NAME column\n",
    "one_hot = pd.get_dummies(med_lab_static_PMH_admdx['DPT_NAME'], prefix='DPT_NAME')\n",
    "med_lab_static_PMH_admdx = med_lab_static_PMH_admdx.drop('DPT_NAME', axis=1).join(one_hot)\n",
    "med_lab_static_PMH_admdx = med_lab_static_PMH_admdx.replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d17c8-014f-4346-b92e-cbb6a0e13456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace special characters in column names with underscores\n",
    "special_chars = [' ', '.', '-', '/', '(', ')', '%', ',', '+', '&', '=']\n",
    "for char in special_chars:\n",
    "    med_lab_static_PMH_admdx.columns = med_lab_static_PMH_admdx.columns.str.replace(char, '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059977b-740e-49ad-96cd-e065ba653f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_lab_static_PMH_admdx_cleaned=med_lab_static_PMH_admdx.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d07ed-2b16-48d1-a613-0cb926e464c2",
   "metadata": {},
   "source": [
    "#### Make descriptive statistics tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a60bd1-4f45-4a36-9ebb-8c895e2cea3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in med_lab_static_PMH_admdx_cleaned[['AGE','BMI','CREATININE_mean','GLUCOSE_POC_mean','GLUCOSE_POC_min','GLUCOSE_POC_last','GLUCOSE_POC_max']].columns:\n",
    "    print('**',x)\n",
    "    median=med_lab_static_PMH_admdx_cleaned[x].median()\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)  \n",
    "    Q1 = med_lab_static_PMH_admdx_cleaned[x].quantile(0.25)  \n",
    "    Q3 = med_lab_static_PMH_admdx_cleaned[x].quantile(0.75)  \n",
    "  \n",
    "    # Calculate the IQR  \n",
    "    IQR = Q3 - Q1  \n",
    "    print(f\"median: {median}\")   \n",
    "    print(f\"Q1: {Q1}\")  \n",
    "    print(f\"Q3: {Q3}\")    \n",
    "# Continuous variables to analyze\n",
    "continuous_vars = ['AGE', 'BMI', 'CREATININE_mean', 'GLUCOSE_POC_mean', \n",
    "                   'GLUCOSE_POC_min', 'GLUCOSE_POC_last', 'GLUCOSE_POC_max']\n",
    "# Loop through each continuous variable \n",
    "for var in med_lab_static_PMH_admdx_cleaned[continuous_vars].columns:\n",
    "    print(f\"** {var} **\")  \n",
    "    # Calculate the median value of the variable\n",
    "    median = med_lab_static_PMH_admdx_cleaned[var].median()\n",
    "    # Calculate the 25th percentile (Q1) and 75th percentile (Q3)\n",
    "    Q1 = med_lab_static_PMH_admdx_cleaned[var].quantile(0.25)\n",
    "    Q3 = med_lab_static_PMH_admdx_cleaned[var].quantile(0.75)\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    # Output the statistical values\n",
    "    print(f\"Median: {median}\")\n",
    "    print(f\"Q1 (25th percentile): {Q1}\")\n",
    "    print(f\"Q3 (75th percentile): {Q3}\")\n",
    "    print(f\"IQR (Interquartile Range): {IQR}\")\n",
    "    print('-' * 40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f091a-840e-4be0-8078-37f4d759561e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical variables: Loop through each column from the specified range\n",
    "categorical_vars = med_lab_static_PMH_admdx_cleaned.iloc[:, 525:].columns\n",
    "# Loop through each categorical variable\n",
    "for var in categorical_vars:\n",
    "    print(f\"** {var} **\")  # Variable name header\n",
    "    count = med_lab_static_PMH_admdx_cleaned[var].value_counts().get(1, 0)\n",
    "    percent = (count / med_lab_static_PMH_admdx_cleaned.shape[0]) * 100\n",
    "    # Output the count and percentage\n",
    "    print(f\"Count of '1': {count}\")\n",
    "    print(f\"Percentage: {percent:.2f}%\")\n",
    "    print('-' * 40)  # Divider for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd143282-8681-4d36-9861-93679f083c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature extract with Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb58eff-5e05-439a-a801-cd5e56091e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable (y) and feature set (X)\n",
    "y = med_lab_static_PMH_admdx_cleaned['ORD_VALUE']  # Target variable\n",
    "X = med_lab_static_PMH_admdx_cleaned.drop(['ORD_VALUE', 'CSN', 'MRN'], axis=1)  # Feature set, excluding non-relevant columns\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training data into training and validation sets (80% of training set for training, 20% for validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1321bef-0842-4bdf-861c-8b28d48e40bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a list of alpha values to test, ranging from 10^-4 to 10^4\n",
    "alphas = np.logspace(-4, 4, 100)  # 100 values on a log scale between 10^-4 and 10^4\n",
    "# Initialize and fit the LassoCV model with 5-fold cross-validation\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=42)  # 5-fold CV ensures a robust model\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "# Retrieve the best alpha value found during cross-validation\n",
    "best_alpha = lasso_cv.alpha_\n",
    "print(f'The optimal alpha value found: {best_alpha}')\n",
    "# Extract the list of alpha values and the corresponding MSE path for each fold\n",
    "alphas = lasso_cv.alphas_  # Alpha values explored by LassoCV\n",
    "mse_path = lasso_cv.mse_path_  # Mean squared error for each fold and alpha\n",
    "# Plot MSE vs. log(alpha) for each fold\n",
    "plt.figure(figsize=(7, 5))\n",
    "for i in range(mse_path.shape[1]):\n",
    "    plt.plot(np.log10(alphas), mse_path[:, i], label=f'Fold {i+1}')  # Log scale of alpha on x-axis\n",
    "# Customize the plot \n",
    "plt.xlabel('Log10(alpha)', fontsize=30) \n",
    "plt.ylabel('MSE', fontsize=30)          \n",
    "plt.tick_params(axis='x', labelsize=25)  \n",
    "plt.tick_params(axis='y', labelsize=25)  \n",
    "plt.legend(fontsize=20)                  \n",
    "plt.tight_layout()                       \n",
    "# Save the figure\n",
    "# plt.savefig('figures/MSEvalpha.svg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea2434-44e8-49f3-a206-4b893e2fa572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the fitted lasso_cv model to predict the target variable on the validation data\n",
    "y_pred = lasso_cv.predict(X_val)\n",
    "# Evaluate the model performance using the R^2 score\n",
    "r2_lasso = lasso_cv.score(X_val, y_val)  \n",
    "print(f'R^2 score on validation data: {r2_lasso}')  \n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'MSE on validation data: {mse}') \n",
    "# Calculate the Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse) \n",
    "print(f'RMSE on validation data: {rmse}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125d0a1-3345-4e8c-b8e4-91d1b5a12062",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(7,5.5))\n",
    "display = PredictionErrorDisplay.from_predictions(\n",
    "    y_val, y_pred, kind=\"actual_vs_predicted\", ax=ax, scatter_kwargs={\"color\": \"skyblue\", \"edgecolor\": \"black\", \"alpha\": 0.5}\n",
    ")\n",
    "plt.xlabel('Predicted', fontsize=35)\n",
    "plt.ylabel('Actual', fontsize=35)\n",
    "plt.tick_params(axis='y', labelsize=30)  \n",
    "plt.tick_params(axis='x', labelsize=30)  \n",
    "plt.tight_layout()\n",
    "plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "#plt.savefig('figures/lasso_actual_vs_predicted.svg', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d2da8-b3e6-4694-8ba5-ee57ee16caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients from the model  \n",
    "coefficients = lasso_cv.coef_  \n",
    "# Pair feature names with their corresponding coefficients  \n",
    "feature_coefficients = list(zip(X_train.columns, coefficients))  \n",
    "# Sort features by the absolute values of their coefficients in descending order  \n",
    "feature_coefficients = sorted(feature_coefficients, key=lambda x: abs(x[1]), reverse=True)  \n",
    "# Separate the feature names and their corresponding coefficients for plotting  \n",
    "sorted_features, sorted_coefficients = zip(*feature_coefficients)  \n",
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(coefficients,bins=50, log=True,color='skyblue', edgecolor='black', linewidth=0.5)\n",
    "plt.xlabel('Lasso Coefficients', fontsize=18)\n",
    "plt.ylabel('Logged Counts', fontsize=18)\n",
    "plt.tick_params(axis='both', labelsize=15)  \n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/lasso_coeff_hist.svg', dpi=300)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed626a05-bf45-4699-9626-de20d92a5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation \n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=0)   \n",
    "cv_model = cross_validate(  \n",
    "    Lasso(alpha=lasso_cv.alpha_, max_iter=10000, random_state=42),  \n",
    "    X_train, y_train,\n",
    "    cv=cv,  \n",
    "    return_estimator=True,  \n",
    "    n_jobs=-1,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3b925-8238-412e-b86d-c2f924e208d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficients from each fold and repeat  \n",
    "coefs = [est.coef_ for est in cv_model['estimator']]  \n",
    "coefs_df = pd.DataFrame(coefs, columns=X_train.columns) \n",
    "# Calculate the mean absolute coefficient value for each feature  \n",
    "mean_coefs = coefs_df.abs().mean().sort_values(ascending=False)  \n",
    "# Select the names of the top 25 features with the highest mean coefficient value  \n",
    "top_25_feature_names = mean_coefs.head(25).index  \n",
    "# Subset the original DataFrame to include only the top 25 features  \n",
    "top_25_coefs_df = coefs_df[top_25_feature_names]  \n",
    "mean_coefs_df=pd.DataFrame(mean_coefs)\n",
    "mean_coefs_df.columns = ['mean absolute value coefficient']\n",
    "#select top 50 features \n",
    "top_50_feature_names = mean_coefs.head(50).index  \n",
    "# Plot the coefficient variability for the top 25 features using a boxplot  \n",
    "plt.figure(figsize=(9, 6))  \n",
    "sns.boxplot(data=top_25_coefs_df, orient=\"h\", color=\"skyblue\")  \n",
    "plt.axvline(x=0, color=\"grey\", linestyle=\"--\")  \n",
    "plt.xlabel(\"Coefficient value\", fontsize=22)  \n",
    "plt.ylabel(\"Features\",fontsize=22)  \n",
    "plt.tick_params(axis='both', labelsize=13) \n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/coeff_var_lasso.svg', dpi=300)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512f5e2-e4e2-4f22-962c-e06e62328998",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear mixed effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68e759-9e0d-460a-8b1d-0056d6162913",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_feature_names = top_50_feature_names.to_list()\n",
    "top_50_feature_names.append('MRN')  # 'MRN' (Medical Record Number) is often used as an identifier for patients in the dataset\n",
    "top_50_feature_names.append('ORD_VALUE')  # 'ORD_VALUE' is the target variable, representing the outcome to be predicted\n",
    "# Select the top 50 features along with 'MRN' and 'ORD_VALUE' from the cleaned DataFrame\n",
    "inputs_lasso = med_lab_static_PMH_admdx_cleaned[top_50_feature_names]  # Subset the DataFrame using the list of selected features\n",
    "# Define the feature matrix 'X' and the target variable 'y' for model training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    inputs_lasso, y,  \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bfeca-16dd-4aae-8f95-4fe4bab633e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LMM Using training set\n",
    "column_list = X_train.columns.to_list()\n",
    "column_list = [col for col in column_list if col not in ['MRN', 'ORD_VALUE']]\n",
    "formula = 'ORD_VALUE ~ ' + ' + '.join(column_list)\n",
    "md = smf.mixedlm(formula, X_train, groups=X_train[\"MRN\"])\n",
    "mdf = md.fit()\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94149474-3899-4bfc-9b14-bb8b5d8f670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set and report metrics\n",
    "y_pred = mdf.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r_squared)\n",
    "mean_squared_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc70c9-9f62-4d81-818f-92ca2a0726f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple testing correction using Benjamini-Hochberg \n",
    "adj_p = statsmodels.stats.multitest.multipletests(\n",
    "    pvals=mdf.pvalues.to_list(), \n",
    "    alpha=0.01,                  \n",
    "    method=\"fdr_bh\"               \n",
    ")\n",
    "summary_frame = mdf.summary().tables[1]\n",
    "dict = {\n",
    "    'variable': mdf.pvalues.index,  \n",
    "    'unadjusted_p_value': mdf.pvalues.to_list(),  \n",
    "    'adjusted_p_value': adj_p[1],  # Adjusted p-values after correction\n",
    "    'coefficient': summary_frame['Coef.'], \n",
    "    'standard error': summary_frame['Std.Err.'],  \n",
    "    '95CI_lower': summary_frame['[0.025'],  \n",
    "    '95CI_upper': summary_frame['0.975]']\n",
    "}\n",
    "df = pd.DataFrame(dict).set_index('variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f7e96-9fcf-4391-a650-f33225b5a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_24h=df[df['adjusted_p_value']<0.05].sort_values(by='adjusted_p_value').reset_index().variable.to_list()\n",
    "items_to_remove = {'Group Var','Intercept'}\n",
    "sig_24h = [item for item in sig_24h if item not in items_to_remove]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv2)",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
